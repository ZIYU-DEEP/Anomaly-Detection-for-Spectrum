{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change TXT Data into Numpy Array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Modify the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 1000\n",
    "normality = 'abnormal'\n",
    "source = '0208_anomaly'\n",
    "outname = '{}_{}_{}_rss.npy'.format(source, normality, str(window_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'joblib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-9d5c50744c4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'joblib'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import joblib\n",
    "import sys\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/net/adv_spectrum/data/rss/downsample_10/abnormal/0208_anomaly/\n",
      "/net/adv_spectrum/array_data_rss/0208_anomaly_abnormal_1000_rss.npy\n"
     ]
    }
   ],
   "source": [
    "input_path = '/net/adv_spectrum/data/rss/downsample_10/{}/{}/'.format(normality, source)\n",
    "output_file = '/net/adv_spectrum/array_data_rss/{}'.format(outname)\n",
    "print(input_path)\n",
    "print(output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Run the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt_to_series(input_path):\n",
    "    features = []\n",
    "\n",
    "    with open(input_path, 'r') as f:\n",
    "        for line in f:\n",
    "            x = line.split()\n",
    "            features.append(x)\n",
    "\n",
    "    return np.array(features).reshape((-1, 1)).astype('float64')\n",
    "\n",
    "\n",
    "def array_to_window(X, window_size):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        X (np.array): Its shape should be (n_time_steps, n_features)\n",
    "        window_size (int): the number of time steps in a window\n",
    "        \n",
    "    Return:\n",
    "        result (np.array): Its shape should be (n_windows, window_size, n_features)\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    ind = np.arange(0, X.shape[0], window_size)\n",
    "    \n",
    "    for start, end in zip(ind, np.r_[ind[1:], X.shape[0]]):\n",
    "        if end - start < window_size:\n",
    "            # Discard the last few lines\n",
    "            break\n",
    "        result.append(X[start:end, :])\n",
    "        \n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/net/adv_spectrum/data/rss/downsample_10/abnormal/ryerson_ab_train_sigOver/1518561613_880M_5m_sigOver_rss.txt\n",
      "(156214, 1)\n",
      "/net/adv_spectrum/data/rss/downsample_10/abnormal/ryerson_ab_train_sigOver/1518564397_880M_5m_sigOver_rss.txt\n",
      "(156214, 1)\n",
      "/net/adv_spectrum/data/rss/downsample_10/abnormal/ryerson_ab_train_sigOver/1518565194_880M_5m_sigOver_rss.txt\n",
      "(156214, 1)\n",
      "/net/adv_spectrum/data/rss/downsample_10/abnormal/ryerson_ab_train_sigOver/1518574357_880M_5m_sigOver_rss.txt\n",
      "(156214, 1)\n",
      "/net/adv_spectrum/data/rss/downsample_10/abnormal/ryerson_ab_train_sigOver/1518586722_880M_5m_sigOver_rss.txt\n",
      "(156214, 1)\n",
      "/net/adv_spectrum/data/rss/downsample_10/abnormal/ryerson_ab_train_sigOver/1518591120_880M_5m_sigOver_rss.txt\n",
      "(156214, 1)\n",
      "/net/adv_spectrum/data/rss/downsample_10/abnormal/ryerson_ab_train_sigOver/1518614667_880M_5m_sigOver_rss.txt\n",
      "(156214, 1)\n",
      "/net/adv_spectrum/data/rss/downsample_10/abnormal/ryerson_ab_train_sigOver/1518618240_880M_5m_sigOver_rss.txt\n",
      "(156214, 1)\n",
      "/net/adv_spectrum/data/rss/downsample_10/abnormal/ryerson_ab_train_sigOver/1518619829_880M_5m_sigOver_rss.txt\n",
      "(156214, 1)\n",
      "/net/adv_spectrum/data/rss/downsample_10/abnormal/ryerson_ab_train_sigOver/1518638930_880M_5m_sigOver_rss.txt\n",
      "(156214, 1)\n",
      "/net/adv_spectrum/data/rss/downsample_10/abnormal/ryerson_ab_train_sigOver/1518652470_880M_5m_sigOver_rss.txt\n",
      "(156214, 1)\n",
      "/net/adv_spectrum/data/rss/downsample_10/abnormal/ryerson_ab_train_sigOver/1518664424_880M_5m_sigOver_rss.txt\n",
      "(156214, 1)\n",
      "/net/adv_spectrum/data/rss/downsample_10/abnormal/ryerson_ab_train_sigOver/1518671203_880M_5m_sigOver_rss.txt\n",
      "(156214, 1)\n",
      "/net/adv_spectrum/data/rss/downsample_10/abnormal/ryerson_ab_train_sigOver/1518678777_880M_5m_sigOver_rss.txt\n",
      "(156214, 1)\n",
      "/net/adv_spectrum/data/rss/downsample_10/abnormal/ryerson_ab_train_sigOver/1518681565_880M_5m_sigOver_rss.txt\n",
      "(156214, 1)\n",
      "/net/adv_spectrum/data/rss/downsample_10/abnormal/ryerson_ab_train_sigOver/1518686752_880M_5m_sigOver_rss.txt\n",
      "(156214, 1)\n",
      "/net/adv_spectrum/data/rss/downsample_10/abnormal/ryerson_ab_train_sigOver/1518693122_880M_5m_sigOver_rss.txt\n",
      "(156214, 1)\n",
      "/net/adv_spectrum/data/rss/downsample_10/abnormal/ryerson_ab_train_sigOver/1518701887_880M_5m_sigOver_rss.txt\n",
      "(156214, 1)\n",
      "/net/adv_spectrum/data/rss/downsample_10/abnormal/ryerson_ab_train_sigOver/1518721055_880M_5m_sigOver_rss.txt\n",
      "(156214, 1)\n",
      "/net/adv_spectrum/data/rss/downsample_10/abnormal/ryerson_ab_train_sigOver/1518739809_880M_5m_sigOver_rss.txt\n",
      "(156214, 1)\n",
      "/net/adv_spectrum/data/rss/downsample_10/abnormal/ryerson_ab_train_sigOver/1518742201_880M_5m_sigOver_rss.txt\n",
      "(156214, 1)\n",
      "/net/adv_spectrum/data/rss/downsample_10/abnormal/ryerson_ab_train_sigOver/1518776133_880M_5m_sigOver_rss.txt\n",
      "(156214, 1)\n",
      "/net/adv_spectrum/data/rss/downsample_10/abnormal/ryerson_ab_train_sigOver/1518810923_880M_5m_sigOver_rss.txt\n",
      "(156214, 1)\n"
     ]
    }
   ],
   "source": [
    "series_list = []\n",
    "\n",
    "for filename in sorted(glob.glob(input_path + '*.txt')):\n",
    "    print(filename)\n",
    "    series = txt_to_series(filename)\n",
    "    print(series.shape)\n",
    "    series_list.append(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting the 0th array to window...\n",
      "Concatenating...\n",
      "\n",
      "Converting the 1th array to window...\n",
      "Concatenating...\n",
      "\n",
      "Converting the 2th array to window...\n",
      "Concatenating...\n",
      "\n",
      "Converting the 3th array to window...\n",
      "Concatenating...\n",
      "\n",
      "Converting the 4th array to window...\n",
      "Concatenating...\n",
      "\n",
      "Converting the 5th array to window...\n",
      "Concatenating...\n",
      "\n",
      "Converting the 6th array to window...\n",
      "Concatenating...\n",
      "\n",
      "Converting the 7th array to window...\n",
      "Concatenating...\n",
      "\n",
      "Converting the 8th array to window...\n",
      "Concatenating...\n",
      "\n",
      "Converting the 9th array to window...\n",
      "Concatenating...\n",
      "\n",
      "Converting the 10th array to window...\n",
      "Concatenating...\n",
      "\n",
      "Converting the 11th array to window...\n",
      "Concatenating...\n",
      "\n",
      "Converting the 12th array to window...\n",
      "Concatenating...\n",
      "\n",
      "Converting the 13th array to window...\n",
      "Concatenating...\n",
      "\n",
      "Converting the 14th array to window...\n",
      "Concatenating...\n",
      "\n",
      "Converting the 15th array to window...\n",
      "Concatenating...\n",
      "\n",
      "Converting the 16th array to window...\n",
      "Concatenating...\n",
      "\n",
      "Converting the 17th array to window...\n",
      "Concatenating...\n",
      "\n",
      "Converting the 18th array to window...\n",
      "Concatenating...\n",
      "\n",
      "Converting the 19th array to window...\n",
      "Concatenating...\n",
      "\n",
      "Converting the 20th array to window...\n",
      "Concatenating...\n",
      "\n",
      "Converting the 21th array to window...\n",
      "Concatenating...\n",
      "\n",
      "Done converting and concatenating!\n"
     ]
    }
   ],
   "source": [
    "X_full= array_to_window(series_list.pop(0), window_size)\n",
    "\n",
    "for i, X in enumerate(series_list):\n",
    "    print('Converting the {}th array to window...'.format(i))\n",
    "    X_windowed = array_to_window(X, window_size)\n",
    "    print('Concatenating...\\n')\n",
    "    X_full = np.concatenate((X_full, X_windowed), axis=0)\n",
    "\n",
    "X_full = X_full.reshape(-1, X_full.shape[1])\n",
    "print('Done converting and concatenating!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3588, 1000)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(output_file, X_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
